{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd13c48",
   "metadata": {},
   "source": [
    "# ì‹œìŠ¤í…œ íŠ¸ë ˆì´ë”© ë¦¬ì„œì¹˜ ë¦¬í¬íŠ¸ (Jupyter Notebook)\n",
    "\n",
    "**ì‘ì„±ì¼:** 2025-08-18 23:45:31\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ *ì‹œê°€/ì§€í‘œ ë³€í™”ìœ¨ ê¸°ë°˜ ì „ëµ*ì„ ì¬í˜„í•˜ê³ , ë°±í…ŒìŠ¤íŠ¸ ë° ë¦¬í¬íŒ…ê¹Œì§€ í•œ ë²ˆì— ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” **í€€íŠ¸ ë¦¬ì„œì¹˜ í…œí”Œë¦¿**ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ë¦¬í¬íŠ¸ êµ¬ì„±\n",
    "1. í™˜ê²½ ì„¤ì • & íŒŒë¼ë¯¸í„°  \n",
    "2. ë°ì´í„° ë¡œë“œ/ì „ì²˜ë¦¬  \n",
    "3. ì „ëµ ë¡œì§ (ì‹œê·¸ë„/ì†ì ˆ)  \n",
    "4. ë°±í…ŒìŠ¤íŠ¸ (ê±°ë˜ ë¡œê·¸/ì¼ë³„ ì†ìµ)  \n",
    "5. ì„±ê³¼ ì§€í‘œ (Sharpe, MDD, CAGR ë“±)  \n",
    "6. ì‹œê°í™” (ì—ì¿¼í‹° ì»¤ë¸Œ, ë“œë¡œë‹¤ìš´)  \n",
    "7. ê²°ê³¼ë¬¼ Export (ì—‘ì…€ ë¦¬í¬íŠ¸)\n",
    "\n",
    "> **ì‚¬ìš© ì „ ì¤€ë¹„ë¬¼:** CSV ë°ì´í„° íŒŒì¼(`mt-10yr-new.csv`)ì´ ë…¸íŠ¸ë¶ê³¼ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11880e",
   "metadata": {},
   "source": [
    "## 1) í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e543266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ & ë°ì´í„° ê³¼í•™ ìŠ¤íƒ\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ì‹œê°í™”: ì§€ì¹¨ìƒ seaborn ì‚¬ìš© ê¸ˆì§€, matplotlibë§Œ ì‚¬ìš©\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ë…¸íŠ¸ë¶ í‘œì‹œ ì˜µì…˜\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 120)\n",
    "\n",
    "print('Env ready:', datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3fc6a2",
   "metadata": {},
   "source": [
    "## 2) íŒŒë¼ë¯¸í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca00a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° íŒŒì¼ëª…\n",
    "file_name = \"mt-10yr-new.csv\"\n",
    "\n",
    "# ì „ëµ íŒŒë¼ë¯¸í„° (í•„ìš”ì‹œ ìˆ˜ì •)\n",
    "rising_rate  = 2.460   # ìƒìŠ¹ êµ¬ê°„ ì¡°ì •ë¥ \n",
    "falling_rate = 2.520   # í•˜ë½ êµ¬ê°„ ì¡°ì •ë¥ \n",
    "\n",
    "# ë°´ë“œ (ì—´ë¦°êµ¬ê°„; idxëŠ” Index6_Pct_Change)\n",
    "a, b = 0.20, 1.31      # ìƒìŠ¹: a < idx < b\n",
    "d, c = -1.05, -0.00    # í•˜ë½: d < idx < c\n",
    "\n",
    "# ìŠ¤íƒ‘ë¡œìŠ¤ (0.004=0.4%), í‹± 0.1\n",
    "sl_buy  = 0.004\n",
    "sl_sell = 0.0165\n",
    "ratio_is_percent = False\n",
    "tick = 0.1\n",
    "\n",
    "print('Parameters loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9447f87",
   "metadata": {},
   "source": [
    "## 3) ë°ì´í„° ë¡œë“œ/ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5437b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV ë¡œë“œ\n",
    "df = pd.read_csv(file_name, header=None)\n",
    "df.columns = [\n",
    "    \"Date\", \"Open\", \"High\", \"Low\", \"Close\",\n",
    "    \"Index1\", \"Index2\", \"Index3\", \"Index4\", \"Index5\",\n",
    "    \"Index6\", \"Index7\", \"Index8\", \"Index9\", \"Index10\", \"Index11\"\n",
    "]\n",
    "\n",
    "# ë‚ ì§œ ì •ê·œí™” (ì‹œê°„ ì œê±°)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.normalize()\n",
    "\n",
    "def pct_change_today_over_yday(s, cur, prev):\n",
    "    # (ê¸ˆì¼ê°’ / ì „ì¼ê°’_ì „ì¼ - 1) * 100\n",
    "    return (s[cur] / s[prev].shift(1) - 1) * 100\n",
    "\n",
    "# ì‹œê°€/Index6 ë³€ë™ë¥  + ì „ì¼ ì¢…ê°€\n",
    "df[\"Open_Pct_Change\"]   = pct_change_today_over_yday(df, \"Open\",  \"Close\")\n",
    "df[\"Index6_Pct_Change\"] = pct_change_today_over_yday(df, \"Index6\",\"Index6\")\n",
    "df[\"Prev_Close\"]        = df[\"Close\"].shift(1)\n",
    "\n",
    "need_cols = [\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Prev_Close\",\"Open_Pct_Change\",\"Index6_Pct_Change\"]\n",
    "df_bt = df.loc[:, need_cols].dropna().reset_index(drop=True).copy()\n",
    "\n",
    "print('Data shape:', df.shape, 'Backtest frame:', df_bt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae60e5",
   "metadata": {},
   "source": [
    "## 4) ì „ëµ ìœ í‹¸/ë¡œì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a84284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ceil_to_nearest(x, step):\n",
    "    return np.ceil(x / step) * step\n",
    "\n",
    "def stop_amount(prev_close, ratio, ratio_is_percent=False, tick=0.1):\n",
    "    amt = prev_close * (ratio*0.01 if ratio_is_percent else ratio)\n",
    "    return ceil_to_nearest(amt, tick)\n",
    "\n",
    "def generate_trades_log(\n",
    "    data,\n",
    "    rising_rate, falling_rate,\n",
    "    a, b, d, c,\n",
    "    sl_buy, sl_sell,\n",
    "    ratio_is_percent=False, tick=0.1\n",
    "):\n",
    "    logs = []\n",
    "    cols = [\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Prev_Close\",\"Open_Pct_Change\",\"Index6_Pct_Change\"]\n",
    "    for Date, O, H, L, C, PrevC, opct, idx in data[cols].itertuples(index=False, name=None):\n",
    "        side = None\n",
    "        band = None\n",
    "        adj  = None\n",
    "        stop = np.nan\n",
    "        stop_hit = False\n",
    "        pnl = 0.0\n",
    "\n",
    "        # ìƒìŠ¹ ë°´ë“œ (ì—´ë¦°êµ¬ê°„)\n",
    "        if (idx > 0) and (a < idx < b):\n",
    "            band = \"RISING\"\n",
    "            adj = idx * rising_rate\n",
    "            if opct > adj:  # BUY\n",
    "                side = \"BUY\"\n",
    "                stop = O - stop_amount(PrevC, sl_buy,  ratio_is_percent, tick)\n",
    "                pnl = (stop - O) if round(L,3) <= round(stop,3) else (C - O)\n",
    "                stop_hit = round(L,3) <= round(stop,3)\n",
    "            elif opct < adj:  # SELL\n",
    "                side = \"SELL\"\n",
    "                stop = O + stop_amount(PrevC, sl_sell, ratio_is_percent, tick)\n",
    "                pnl = (O - stop) if round(H,3) >= round(stop,3) else (O - C)\n",
    "                stop_hit = round(H,3) >= round(stop,3)\n",
    "\n",
    "        # í•˜ë½ ë°´ë“œ (ì—´ë¦°êµ¬ê°„)\n",
    "        elif (idx < 0) and (d < idx < c):\n",
    "            band = \"FALLING\"\n",
    "            adj = idx * falling_rate\n",
    "            if opct < adj:  # SELL\n",
    "                side = \"SELL\"\n",
    "                stop = O + stop_amount(PrevC, sl_sell, ratio_is_percent, tick)\n",
    "                pnl = (O - stop) if round(H,3) >= round(stop,3) else (O - C)\n",
    "                stop_hit = round(H,3) >= round(stop,3)\n",
    "            elif opct > adj:  # BUY\n",
    "                side = \"BUY\"\n",
    "                stop = O - stop_amount(PrevC, sl_buy,  ratio_is_percent, tick)\n",
    "                pnl = (stop - O) if round(L,3) <= round(stop,3) else (C - O)\n",
    "                stop_hit = round(L,3) <= round(stop,3)\n",
    "\n",
    "        if side is None:\n",
    "            continue\n",
    "\n",
    "        logs.append({\n",
    "            \"Date\": Date,\n",
    "            \"Band\": band,\n",
    "            \"IndexChange(%)\": idx,\n",
    "            \"OpenPct(%)\": opct,\n",
    "            \"AdjThreshold(%)\": adj,\n",
    "            \"Side\": side,\n",
    "            \"Entry\": O,\n",
    "            \"Close\": C,\n",
    "            \"Low\": L,\n",
    "            \"High\": H,\n",
    "            \"PrevClose\": PrevC,\n",
    "            \"Stop\": stop,\n",
    "            \"StopHit\": stop_hit,\n",
    "            \"PnL\": float(pnl),\n",
    "        })\n",
    "\n",
    "    trades = pd.DataFrame(logs).sort_values(\"Date\").reset_index(drop=True)\n",
    "    return trades\n",
    "\n",
    "def make_daily_pnl_all_dates(df_all_dates, trades_df):\n",
    "    all_dates = (\n",
    "        df_all_dates[[\"Date\"]]\n",
    "        .drop_duplicates()\n",
    "        .sort_values(\"Date\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if trades_df.empty:\n",
    "        daily = all_dates.copy()\n",
    "        daily[\"DailyPnL\"] = 0.0\n",
    "        daily[\"Trades\"]   = 0\n",
    "        daily[\"CumPnL\"]   = 0.0\n",
    "        return daily\n",
    "\n",
    "    byday = (\n",
    "        trades_df.groupby(\"Date\", as_index=False)\n",
    "        .agg(DailyPnL=(\"PnL\", \"sum\"), Trades=(\"PnL\", \"size\"))\n",
    "    )\n",
    "\n",
    "    daily = all_dates.merge(byday, on=\"Date\", how=\"left\")\n",
    "    daily[\"DailyPnL\"] = daily[\"DailyPnL\"].fillna(0.0)\n",
    "    daily[\"Trades\"]   = daily[\"Trades\"].fillna(0).astype(int)\n",
    "    daily[\"CumPnL\"]   = daily[\"DailyPnL\"].cumsum()\n",
    "    return daily\n",
    "\n",
    "def _fmt(x, nd=2):\n",
    "    s = f\"{x:.{nd}f}\"\n",
    "    return s.replace(\"-0.00\", \"0.00\").replace(\"-0.0\", \"0.0\")\n",
    "\n",
    "print('Strategy functions loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37db038",
   "metadata": {},
   "source": [
    "## 5) ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_df = generate_trades_log(\n",
    "    df_bt,\n",
    "    rising_rate, falling_rate,\n",
    "    a, b, d, c,\n",
    "    sl_buy, sl_sell,\n",
    "    ratio_is_percent=ratio_is_percent, tick=tick\n",
    ")\n",
    "\n",
    "daily_df = make_daily_pnl_all_dates(df, trades_df)\n",
    "\n",
    "print('Trades:', len(trades_df), 'Days:', len(daily_df))\n",
    "trades_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee869ee1",
   "metadata": {},
   "source": [
    "## 6) ì„±ê³¼ ì§€í‘œ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e91fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_stats(daily_df, trades_df):\n",
    "    stats = {}\n",
    "    stats['total_trades'] = int(trades_df.shape[0])\n",
    "    stats['total_pnl'] = float(trades_df['PnL'].sum()) if not trades_df.empty else 0.0\n",
    "    stats['avg_pnl_per_trade'] = float(trades_df['PnL'].mean()) if not trades_df.empty else 0.0\n",
    "    stats['win_rate'] = (trades_df['PnL'] > 0).mean() if not trades_df.empty else 0.0\n",
    "\n",
    "    # ì¼ë³„ ì†ìµ ê¸°ë°˜ ìƒ¤í”„, CAGR, MDD\n",
    "    dd = daily_df.copy()\n",
    "    dd = dd.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # ì¼ìˆ˜ ë° ì—°í™˜ì‚° ê°€ì • (ê±°ë˜ì¼ 252ì¼)\n",
    "    if len(dd) > 1:\n",
    "        days = (dd['Date'].iloc[-1] - dd['Date'].iloc[0]).days\n",
    "    else:\n",
    "        days = 0\n",
    "    years = days / 365.25 if days > 0 else 0\n",
    "\n",
    "    # ì¼ë³„ ìˆ˜ìµë¥  ê°€ì •: PnL ë‹¨ìœ„ê°€ ì ˆëŒ€ê¸ˆì•¡ì´ë©´ ë¹„ìœ¨ í•„ìš”.\n",
    "    # ì—¬ê¸°ì„œëŠ” PnL ìì²´ì˜ ë³€ë™ì„±ìœ¼ë¡œ ìƒ¤í”„ë¥¼ ë‹¨ìˆœ ê·¼ì‚¬(ìŠ¤ì¼€ì¼ ì¡°ì • í•„ìš” ì‹œ ì‚¬ìš©ì ì •ì˜)\n",
    "    ret = dd['DailyPnL'].values\n",
    "    if ret.size > 1 and ret.std(ddof=1) != 0:\n",
    "        sharpe_daily = ret.mean() / ret.std(ddof=1)\n",
    "        sharpe_annual = sharpe_daily * np.sqrt(252)\n",
    "    else:\n",
    "        sharpe_daily = 0.0\n",
    "        sharpe_annual = 0.0\n",
    "\n",
    "    # ì—ì¿¼í‹° ì»¤ë¸Œ ê¸°ë°˜ MDD\n",
    "    equity = dd['CumPnL'].values\n",
    "    if equity.size > 0:\n",
    "        peak = np.maximum.accumulate(equity)\n",
    "        drawdown = equity - peak\n",
    "        mdd = drawdown.min() if drawdown.size > 0 else 0.0\n",
    "    else:\n",
    "        mdd = 0.0\n",
    "\n",
    "    # CAGR: ì ˆëŒ€ PnLë¡œëŠ” ì •ì˜ ì–´ë ¤ì›€. ì´ˆê¸°ìë³¸ 1ë¡œ ê°€ì • ì‹œ êµ¬í˜„ ì˜ˆì‹œ\n",
    "    initial_capital = 1.0\n",
    "    final_capital = initial_capital + (dd['CumPnL'].iloc[-1] if len(dd) else 0.0)\n",
    "    cagr = (final_capital / initial_capital) ** (1/years) - 1 if years > 0 and final_capital > 0 else 0.0\n",
    "\n",
    "    stats.update({\n",
    "        'sharpe_annual(approx)': float(sharpe_annual),\n",
    "        'mdd_abs': float(mdd),\n",
    "        'cagr_assuming_init1': float(cagr),\n",
    "        'period_days': int(days),\n",
    "        'period_years': float(years),\n",
    "    })\n",
    "    return pd.DataFrame([stats])\n",
    "\n",
    "perf = performance_stats(daily_df, trades_df)\n",
    "perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c7aa8",
   "metadata": {},
   "source": [
    "## 7) ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d23b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—ì¿¼í‹° ì»¤ë¸Œ\n",
    "plt.figure()\n",
    "plt.plot(daily_df['Date'], daily_df['CumPnL'])\n",
    "plt.title('Equity Curve (CumPnL)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('CumPnL')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë“œë¡œë‹¤ìš´\n",
    "equity = daily_df['CumPnL'].values\n",
    "if equity.size > 0:\n",
    "    peak = np.maximum.accumulate(equity)\n",
    "    drawdown = equity - peak\n",
    "else:\n",
    "    drawdown = np.array([])\n",
    "\n",
    "plt.figure()\n",
    "if drawdown.size > 0:\n",
    "    plt.plot(daily_df['Date'], drawdown)\n",
    "plt.title('Drawdown (Absolute)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Drawdown')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d169de",
   "metadata": {},
   "source": [
    "## 8) ê²°ê³¼ë¬¼ Export (ì—‘ì…€ ë¦¬í¬íŠ¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = \"mt_kosdaq_trades.xlsx\"\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
    "    trades_df.to_excel(writer, sheet_name=\"trades\", index=False)\n",
    "    daily_df.to_excel(writer, sheet_name=\"daily_pnl\", index=False)\n",
    "    perf.to_excel(writer, sheet_name=\"performance\", index=False)\n",
    "\n",
    "print(f\"ì—‘ì…€ ì €ì¥ ì™„ë£Œ: {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc0e39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ“Œ ìš´ì˜ íŒ\n",
    "- **ê±°ë˜ë¹„ìš©/ìŠ¬ë¦¬í”¼ì§€** ì—´ì„ ì¶”ê°€í•˜ì—¬ í˜„ì‹¤ ë°˜ì˜ (ìˆ˜ìˆ˜ë£Œ/ì„¸ê¸ˆ/ìŠ¤í”„ë ˆë“œ)  \n",
    "- **ì›Œí¬í¬ì›Œë“œ ê²€ì¦**: ê¸°ê°„ ë¶„í• (í›ˆë ¨/ê²€ì¦) + íŒŒë¼ë¯¸í„° ê³ ì • í›„ ê²€ì¦  \n",
    "- **íŒŒë¼ë¯¸í„° ìŠ¤ìœ•**: grid/random/Bayesë¡œ `rising_rate`, `falling_rate`, `a,b,c,d`, `sl_*` ë¯¼ê°ë„ ë¶„ì„  \n",
    "- **ìœ ë‹› í…ŒìŠ¤íŠ¸**: ì„ê³„ì¹˜/ì†ì ˆ íŒì • ë¡œì§ì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¡œ ì¬í˜„ì„± ê°•í™”  \n",
    "- **ë²„ì „ ìŠ¤ëƒ…ìƒ·**: ë°ì´í„° ë²„ì „, íŒŒë¼ë¯¸í„°, ì½”ë“œ í•´ì‹œë¥¼ í•¨ê»˜ ì €ì¥\n",
    "\n",
    "> ì„±ê³¼/ë¦¬ìŠ¤í¬ ì‚°ì¶œ ë°©ì‹ì€ **ì ˆëŒ€ PnL vs ë¹„ìœ¨ ìˆ˜ìµë¥ **ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤. ì‹¤ì œ ìš´ìš©ì—ì„œëŠ” ì´ˆê¸°ìë³¸/í¬ì§€ì…˜ ì‚¬ì´ì¦ˆ/ê±°ë˜ë¹„ìš©ì„ ëª…ì‹œí•˜ê³  í¼í¬ë¨¼ìŠ¤ ì§€í‘œë¥¼ ê³„ì‚°í•˜ì„¸ìš”.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
